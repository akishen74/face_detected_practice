{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "\n",
    "def get_features(img):\n",
    "\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    features = model.predict(x)\n",
    "    avg_features = np.mean(features, axis=(1, 2))\n",
    "    \n",
    "    return avg_features\n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "casc_path = cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(casc_path)\n",
    "\n",
    "filepath = \"image\\\\practice\\\\\"\n",
    "files = os.listdir(filepath)\n",
    "\n",
    "imgs = []\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    savepath = f'output\\\\{file.replace(\".jpg\", \"\")}\\\\'\n",
    "    if not os.path.exists(savepath):\n",
    "        os.makedirs(savepath)    \n",
    "\n",
    "    img = cv2.imread(filepath+file)\n",
    "    cv2.imwrite(savepath+\"0_original.jpg\", img)\n",
    "    faces = faceCascade.detectMultiScale(img, scaleFactor=1.20, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    imgheight = img.shape[0]\n",
    "    imgwidth = img.shape[1]\n",
    "    cv2.rectangle(img, (10, imgheight-20), (110, imgheight), (0, 0, 0), -1)\n",
    "\n",
    "    count = 1\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (128, 255, 0), 2)\n",
    "\n",
    "        facename = savepath + f\"2_face_{str(count)}.jpg\"\n",
    "        face = img[y: y+h, x: x+w]\n",
    "        face = cv2.resize(face, (32, 32))\n",
    "        cv2.imwrite(facename, face)        \n",
    "\n",
    "        face_pil = Image.fromarray(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
    "        imgs_rgb = []\n",
    "        imgs_grey = []\n",
    "\n",
    "        for i in range(8, 0, -1):\n",
    "            quantized_image = face_pil.quantize(colors=2**i)\n",
    "\n",
    "            if i == 3:\n",
    "                feature = get_features(quantized_image.convert(\"RGB\"))\n",
    "                np.savetxt(f\"{savepath}7_face_{str(count)}_feature.csv\", feature)\n",
    "\n",
    "            quantized_image_rgb = quantized_image.convert(\"RGB\")            \n",
    "            imgs_rgb.append(quantized_image_rgb)\n",
    "            rgb_array = np.array(quantized_image_rgb)     \n",
    "\n",
    "            \n",
    "\n",
    "            with open(f\"{savepath}4_face_{str(count)}_rgb_{str(2**i)}.csv\", \"w\") as f:\n",
    "                f.write(\"\\t\" + \"\\t\".join([str(n) for n in range(rgb_array.shape[1])]) + \"\\n\")\n",
    "                for ii in range(rgb_array.shape[0]):\n",
    "                    f.write(f\"{str(ii)}\\t\")\n",
    "                    for jj in range(rgb_array.shape[1]):\n",
    "                        line = f\"[{rgb_array[ii, jj, 0]}, {rgb_array[ii, jj, 1]}, {rgb_array[ii, jj, 2]}]\"\n",
    "                        if jj < rgb_array.shape[1] - 1:\n",
    "                            line += \"\\t\"\n",
    "                        f.write(line)\n",
    "                    if ii < rgb_array.shape[0] - 1:\n",
    "                        f.write(\"\\n\")\n",
    "\n",
    "            quantized_image_gray = quantized_image.convert(\"L\")\n",
    "            imgs_grey.append(quantized_image_gray)\n",
    "            gray_array = np.array(quantized_image_gray)            \n",
    "            gray_array = pd.DataFrame(gray_array)\n",
    "            gray_array.to_csv(f\"{savepath}6_face_{str(count)}_gray_{str(2**i)}.csv\", sep=\"\\t\")\n",
    "\n",
    "        fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            ax.imshow(np.array(imgs_rgb[i]))\n",
    "            ax.axis('off')\n",
    "\n",
    "        face_gird = savepath + f\"3_face_{str(count)}_rgb_grid.jpg\"\n",
    "        plt.savefig(face_gird)\n",
    "\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            ax.imshow(np.array(imgs_grey[i]), cmap=\"gray\")\n",
    "            ax.axis('off')\n",
    "\n",
    "        face_gird = savepath + f\"5_face_{str(count)}_gray_grid.jpg\"\n",
    "        plt.savefig(face_gird)\n",
    "        plt.close()\n",
    "\n",
    "        count+=1\n",
    "\n",
    "    cv2.imwrite(savepath+\"1_detected.jpg\", img)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
