{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Calculation:\n",
      "Actual Value: 3\n",
      "Predicted Value: 3.05\n",
      "Mean Squared Error (MSE) from Manual Calculation: 0.0024999999999999823\n"
     ]
    }
   ],
   "source": [
    "def mean_squared_error(actual, predicted):\n",
    "    \"\"\"\n",
    "    計算Mean Squared Error (MSE)\n",
    "    \n",
    "    參數：\n",
    "    actual: 實際值的陣列或列表\n",
    "    predicted: 預測值的陣列或列表，與實際值對應\n",
    "    \n",
    "    返回值：\n",
    "    MSE值\n",
    "    \"\"\"\n",
    "    # 確保actual與predicted的長度相同\n",
    "    if len(actual) != len(predicted):\n",
    "        raise ValueError(\"actual與predicted的長度必須相同\")\n",
    "    \n",
    "    # 計算MSE\n",
    "    squared_errors = [(actual[i] - predicted[i]) ** 2 for i in range(len(actual))]\n",
    "    mse = sum(squared_errors) / len(actual)\n",
    "    return mse\n",
    "\n",
    "\n",
    "\n",
    "def L(u, v):\n",
    "    return 3*u**2 + 3*v**2 - u*v + 7*u - 7*v + 10\n",
    "\n",
    "# 代入 (u, v) = (-1, 1)\n",
    "\n",
    "# 手動計算實際值和預測值\n",
    "actual_value_manual = L(-1, 1)\n",
    "predicted_value_manual = L(-1.1, 0.9)\n",
    "\n",
    "# 使用相同的程式碼計算 MSE\n",
    "mse_manual = mean_squared_error([actual_value_manual], [predicted_value_manual])\n",
    "\n",
    "# 輸出手動計算的實際值和預測值，以及對應的 MSE\n",
    "print(\"Manual Calculation:\")\n",
    "print(\"Actual Value:\", actual_value_manual)\n",
    "print(\"Predicted Value:\", predicted_value_manual)\n",
    "print(\"Mean Squared Error (MSE) from Manual Calculation:\", mse_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小值的參數向量: [-1.  1.]\n",
      "對應的函數值 L(u, v): 3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_descent(initial_theta, learning_rate, num_iterations, gradient_function):\n",
    "    \"\"\"\n",
    "    使用梯度下降法尋找函數的最小值\n",
    "    \n",
    "    參數：\n",
    "    initial_theta: 初始的參數向量\n",
    "    learning_rate: 學習速率（步長）\n",
    "    num_iterations: 迭代次數\n",
    "    gradient_function: 梯度函數，返回給定參數下的梯度向量\n",
    "    \n",
    "    返回值：\n",
    "    最小值的參數向量\n",
    "    \"\"\"\n",
    "    theta = initial_theta\n",
    "    for _ in range(num_iterations):\n",
    "        gradient = gradient_function(theta)\n",
    "        theta = theta - learning_rate * gradient\n",
    "    return theta\n",
    "\n",
    "# 定義函數 L(a, b)\n",
    "def L(u, v):\n",
    "    return 3*u**2 + 3*v**2 - u*v + 7*u - 7*v + 10\n",
    "\n",
    "# 成本函數\n",
    "def cost_function(theta):\n",
    "    \"\"\"\n",
    "    成本函數，即 L(a, b)\n",
    "    \"\"\"\n",
    "    return L(theta[0], theta[1])\n",
    "\n",
    "# 梯度函數\n",
    "def gradient_function(theta):\n",
    "    \"\"\" \n",
    "    成本函數的梯度函數\n",
    "    \"\"\"\n",
    "    du = 6*theta[0] - theta[1] + 7\n",
    "    dv = 6*theta[1] - theta[0] - 7\n",
    "    return np.array([du, dv])\n",
    "\n",
    "# 初始參數向量\n",
    "initial_theta = np.array([0, 0])\n",
    "# 學習速率\n",
    "learning_rate = 0.1\n",
    "# 迭代次數\n",
    "num_iterations = 100\n",
    "\n",
    "# 使用梯度下降法尋找最小值\n",
    "final_theta = gradient_descent(initial_theta, learning_rate, num_iterations, gradient_function)\n",
    "\n",
    "print(\"最小值的參數向量:\", final_theta)\n",
    "print(\"對應的函數值 L(u, v):\", L(final_theta[0], final_theta[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradient_function(theta):\n",
    "    \"\"\" \n",
    "    成本函數的梯度函數\n",
    "    \"\"\"\n",
    "    du = 6*theta[0] - theta[1] + 7\n",
    "    dv = 6*theta[1] - theta[0] - 7\n",
    "    return np.array([du, dv])\n",
    "\n",
    "gradient_function(np.array([-1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 3 (2517262879.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    L = 3*u**2 + 3*v**2 - u*v + 7*u - 7*v + 10\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 3\n"
     ]
    }
   ],
   "source": [
    "import sympy as sp\n",
    "\n",
    "def gradient_function(theta):\n",
    "    \n",
    "# 定義函數\n",
    "L = 3*u**2 + 3*v**2 - u*v + 7*u - 7*v + 10\n",
    "    \n",
    "u, v = sp.symbols('u v')\n",
    "\n",
    "# 計算梯度\n",
    "du = sp.diff(L, u)\n",
    "dv = sp.diff(L, v)\n",
    "\n",
    "# 將 u 和 v 替換為特定的數值\n",
    "du_value = du.subs({u: -1, v: 1})\n",
    "dv_value = dv.subs({u: -1, v: 1})\n",
    "\n",
    "# 轉換為數值\n",
    "du_numeric = float(du_value)\n",
    "dv_numeric = float(dv_value)\n",
    "\n",
    "gradient = np.array([du_numeric, dv_numeric])\n",
    "\n",
    "# 打印梯度\n",
    "print(\"梯度:\", gradient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "du 的數值: 11\n",
      "dv 的數值: 4\n"
     ]
    }
   ],
   "source": [
    "import sympy as sp\n",
    "\n",
    "# 定義符號變量\n",
    "u, v = sp.symbols('u v')\n",
    "\n",
    "# 定義表達式\n",
    "L = 3*u**2 + 3*v**2 - u*v + 7*u - 7*v + 10\n",
    "\n",
    "# 求導數\n",
    "du = sp.diff(L, u)\n",
    "dv = sp.diff(L, v)\n",
    "\n",
    "# 將導數轉換為數值\n",
    "u_val = 1  # u 的值\n",
    "v_val = 2  # v 的值\n",
    "du_val = du.subs([(u, u_val), (v, v_val)])\n",
    "dv_val = dv.subs([(u, u_val), (v, v_val)])\n",
    "\n",
    "print(\"du 的數值:\", du_val)\n",
    "print(\"dv 的數值:\", dv_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - u + 6 v - 7$"
      ],
      "text/plain": [
       "-u + 6*v - 7"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def L(u, v):\n",
    "    return 3*u**2 + 3*v**2 - u*v + 7*u - 7*v + 10\n",
    "\n",
    "cntner = []\n",
    "for a, b in zip([np.random.randint(20) for i in range(0, 10)], [np.random.randint(20) for i in range(0, 10)]):\n",
    "    cntner.append([a, b, L(a, b)])\n",
    "    \n",
    "train = np.array(cntner)\n",
    "\n",
    "train_x = [train[:, 0], train[:, 1]]\n",
    "train_x = np.vstack((train_x[0], train_x[1])).transpose()\n",
    "train_y = train[:, 2]\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 10\n",
      "-2 2 10\n",
      "-4 4 66\n",
      "-6 6 178\n",
      "-8 8 346\n",
      "-10 10 570\n",
      "-12 12 850\n",
      "-14 14 1186\n",
      "-16 16 1578\n",
      "-18 18 2026\n",
      "手刻預測值: -14034303238987587455020149574431202368359344707667789757605217096806911548217895219507042299987539343129444352\n",
      "Sklearn: 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def L(u, v):\n",
    "    return 3*u**2 + 3*v**2 - u*v + 7*u - 7*v + 10\n",
    "\n",
    "cntner = []\n",
    "for a, b in zip([i for i in range(0, -20, -2)], [i for i in range(0, 20, 2)]):\n",
    "    print(a, b, L(a, b))\n",
    "    cntner.append([a, b, L(a, b)])\n",
    "    \n",
    "train = np.array(cntner)\n",
    "\n",
    "train_x = train[:,:2]\n",
    "train_y = train[:, 2]\n",
    "\n",
    "theta = np.random.rand(2)\n",
    "\n",
    "def f(x):\n",
    "    return np.dot(x, theta)\n",
    "\n",
    "def E(x,y):\n",
    "    return 0.5* np.sum((y - f(x)) ** 2)\n",
    "\n",
    "ETA = 0.001\n",
    "n_iter = 1000\n",
    "\n",
    "error = E(train_x, train_y)\n",
    "\n",
    "while n_iter > 0:\n",
    "    \n",
    "    theta = theta - ETA * np.dot(f(train_x) - train_y, train_x)    \n",
    "    current_error = E(train_x, train_y) \n",
    "    n_iter -= 1\n",
    "\n",
    "test = np.array([-1, 1])\n",
    "pred = f(test)\n",
    "print(\"手刻預測值:\", int(pred))\n",
    "\n",
    "\n",
    "# sklearn\n",
    "model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "model.fit(train_x, train_y)\n",
    "test = np.array([[-1, 1]])\n",
    "pred = model.predict(test)\n",
    "print(\"Sklearn:\", int(pred[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85859424, 0.49566981])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('polynomialfeatures', PolynomialFeatures()),\n",
       "  ('linearregression', LinearRegression())],\n",
       " 'verbose': False,\n",
       " 'polynomialfeatures': PolynomialFeatures(),\n",
       " 'linearregression': LinearRegression(),\n",
       " 'polynomialfeatures__degree': 2,\n",
       " 'polynomialfeatures__include_bias': True,\n",
       " 'polynomialfeatures__interaction_only': False,\n",
       " 'polynomialfeatures__order': 'C',\n",
       " 'linearregression__copy_X': True,\n",
       " 'linearregression__fit_intercept': True,\n",
       " 'linearregression__n_jobs': None,\n",
       " 'linearregression__positive': False}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
